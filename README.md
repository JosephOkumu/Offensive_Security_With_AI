# Offensive Security With AI
Introduction to the intersection of Offensive Security and Artificial Intelligence (AI)
## Tools and Frameworks for Understanding ML Attacks

| Tool                     | Description                                   | Use Case                    |
|--------------------------|-----------------------------------------------|-----------------------------|
| **CleverHans**           | TensorFlow/PyTorch library for adversarial attack crafting | Evasion testing             |
| **Foolbox**              | Python toolkit for white-box and black-box attacks | Robustness validation       |
| **ART (Adversarial Robustness Toolbox)** | IBM's security-focused ML toolkit | Poisoning, inference attacks |
| **Tramer's KnockoffNets** | Academic codebase for model theft simulations | Model extraction            |
| **PromptInject & Gauntlet** | Tools for prompt injection testing            | LLM adversarial inputs      |

- Think Like an Adversary of the Model, Not the App: AI security â‰  web/API security.
- Start with Inference First: It is often the most exposed and unprotected point.
